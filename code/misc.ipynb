{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarabic.araby as araby\n",
    "import pyarabic.number as number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to decode text\n",
    "def decode(l):\n",
    "\t#     l = l.replace(\"+\", \"#\")\n",
    "    # there is an unexpected case in disambig results - #A #B#. \n",
    "    # we are unsure of whether to split or merge this case, and currently we are spliting\n",
    "    l = l.replace(\"# #\", \"\").replace(\"+ \", \"\").replace(\"</s>\", \"\").replace(\"<s>\", \"\")\n",
    "    l = l.replace(\"# #\", \"\").replace(\"+ \", \"\").replace(\"</s>\", \"\").replace(\"<s>\", \"\")\n",
    "    l = l.replace(\"# \", \" \").replace(\" #\", \" \")\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arabic letters range\n",
    "begin = int(\"0600\", 16)\n",
    "end = int(\"06FF\", 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test =\"\"\" ١٢٦  \n",
    " فميا دعج  ) من مرآها . لكنها لم تكن تلتفت إلى ماوراء ذلك من  \n",
    " تقلت المعانى وتعدد الشخوص  \n",
    " فإنهما لز يوم رائق صاف بميل الأصيل وهمام يتأمل وجهها  \n",
    " الذى تسدل الأشعة والظلال من معانيه كل لحظة ، وتبدل العو اطف  \n",
    " والخلجات من ملامحه كل فترة ، إذا به يهتف نجاة بكات لا مقدمة  \n",
    " لها ولا سارقة لتفسيرها .  \n",
    " كلك  من وجوه باسارة.!  \n",
    " فانتفضت فى ذراعه ، وحسبت أبها مقسمة لاتهام وملاحاة ،  \n",
    " وهما يستمرآن نه ذلك اليوم الرائق الصاف ابلجيل ، وقالت :  \n",
    " ماذا تمن؟  \n",
    " قال : هت ى من روعك . إما ثناء أردت لاملامة، وأخذ  \n",
    " يشرح لها ما يعنه كأنه حدثها عن امرأة غائية أو عن شخص من  \n",
    " شخو ص الروانات ، وه تصغى إليه مسبوتة ، م مسبر بحة ، ممبتسمه  \n",
    " م طروبا متهالة ، وهو يرى فيا يري مصداق ما يلاحظه عليا  \n",
    " وتحدثها عنه ، حتى كار ختام الحديت اقتراب الشفاه داهة  \n",
    " وطواعية.. منكتة من نـكاتها التى لا تخذلها في أمثال هذه المواقي ...  \n",
    " ألقتها إليه وه تنناءى عنه مرحة ضاحي  \n",
    " امد ربك . عندك من سارة المظلومة حربم كامل ، فلا تشكر  \n",
    " تفسك كثيرا عل الوفاء !  \n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = \"\"\"\n",
    " كيفف رزيا ?  \n",
    " رتيب الحوادث أن تنبى م نـكر راجعين للسؤال عن بدايتها  \n",
    " وسبيل التوارخ أن تنطوى السير وتنصرم الدول م نتقصى  \n",
    " ستاشمها وأسباب فلوورما  \n",
    " فتحن لانخدء  ف يرق الزمان حين أمرف الساعة كف  \n",
    " تلاقت سارة وشمام ، بعد أن عرفتا منذ رهة كف كانت القطعة  \n",
    " وكيف كان اللقاء الأخير  \n",
    " لم يقصد همام أن يلتق بسارة ولم تقصد سارة أن تكت بهمام...  \n",
    " وإما جاء اللقاء ا تيء مع  ظ الحوادث الكببى في معظ التواريخ  \n",
    " والسير : من زواج وفراق ورحلة واختيار مساع واقتحام غيوب ،  \n",
    " مصادفة لا يسقها عمد، وعرضا لا مهده له تتفكير  \n",
    " ع ام \"ى ف الجلاء جرة مري  تهر ان الكر يف التى  \n",
    " تدج فيها الشمس فى هدوء، ويرقص فيها الهواء فى حزين ، ويرق فيها  \n",
    " الجو ف تشوف وارتقاب ، وتطرح فيها النفس أعباءها كا تطرح  \n",
    " القافلة أحاها عند مشارفة الواحة المبشرة بالماء الفزر والظل  \n",
    " الظلل : ررثيا تهض بالعبه من جديد  \n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to encode text\n",
    "def encode(line):\n",
    "    new_l = []\n",
    "    line = araby.strip_shadda(araby.strip_harakat(line)).replace(\"آ\", \"ا\").replace(\"إ\", \"ا\").replace(\"أ\", \"ا\")\n",
    "    new_line = \"\"\n",
    "    for letter in line:\n",
    "        if (ord(letter) < begin or ord(letter) > end) and (letter!=' '):\n",
    "            continue\n",
    "        new_line = new_line + letter\n",
    "    line = new_line\n",
    "    \n",
    "    for w in line.split():\n",
    "        i = 0\n",
    "       \tfor c in w:\n",
    "            if len(w)==1:\n",
    "                new_l.append(c)\n",
    "            elif i == len(w) - 1:\n",
    "                new_l.append(\"#\" + c)\n",
    "            elif i == 0:\n",
    "                new_l.append(c + \"#\")\n",
    "            else:\n",
    "                new_l.append(\"#\" + c + \"#\")\n",
    "            i += 1\n",
    "    return \"<s> \" + \" \".join(new_l) + \" </s>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "badboy = \"\\n\".join([encode(t) for t in test2.split(\"\\n\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad = open(\"bad.txt\", \"w\")\n",
    "bad.write(badboy)\n",
    "bad.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = \"\"\n",
    "original_file = open(\"data/columbia_aco000270/columbia_aco000270_raw_ocr/ocr_space_output_126.txt\", \"r\")\n",
    "for line in original_file:\n",
    "    encoded_text = encoded_text + encode(line) + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> ١# #٢# #٦ </s>\\n<s> ف# #م# #ي# #ا د# #ع# #ج م# #ن م# #ر# #ا# #ه# #ا ل# #ك# #ن# #ه# #ا ل# #م ت# #ك# #ن ت# #ل# #ت# #ف# #ت ا# #ل# #ى م# #ا# #و# #ر# #ا# #ء ذ# #ل# #ك م# #ن </s>\\n<s> ت# #ق# #ل# #ت ا# #ل# #م# #ع# #ا# #ن# #ى و# #ت# #ع# #د# #د ا# #ل# #ش# #خ# #و# #ص </s>\\n<s> ف# #ا# #ن# #ه# #م# #ا ل# #ز ي# #و# #م ر# #ا# #ئ# #ق ص# #ا# #ف ب# #م# #ي# #ل ا# #ل# #ا# #ص# #ي# #ل و# #ه# #م# #ا# #م ي# #ت# #ا# #م# #ل و# #ج# #ه# #ه# #ا </s>\\n<s> ا# #ل# #ذ# #ى ت# #س# #د# #ل ا# #ل# #ا# #ش# #ع# #ة و# #ا# #ل# #ظ# #ل# #ا# #ل م# #ن م# #ع# #ا# #ن# #ي# #ه ك# #ل ل# #ح# #ظ# #ة ، و# #ت# #ب# #د# #ل ا# #ل# #ع# #و ا# #ط# #ف </s>\\n<s> و# #ا# #ل# #خ# #ل# #ج# #ا# #ت م# #ن م# #ل# #ا# #م# #ح# #ه ك# #ل ف# #ت# #ر# #ة ، ا# #ذ# #ا ب# #ه ي# #ه# #ت# #ف ن# #ج# #ا# #ة ب# #ك# #ا# #ت ل# #ا م# #ق# #د# #م# #ة </s>\\n<s> ل# #ه# #ا و# #ل# #ا س# #ا# #ر# #ق# #ة ل# #ت# #ف# #س# #ي# #ر# #ه# #ا </s>\\n<s> ك# #ل# #ك م# #ن و# #ج# #و# #ه ب# #ا# #س# #ا# #ر# #ة </s>\\n<s> ف# #ا# #ن# #ت# #ف# #ض# #ت ف# #ى ذ# #ر# #ا# #ع# #ه ، و# #ح# #س# #ب# #ت ا# #ب# #ه# #ا م# #ق# #س# #م# #ة ل# #ا# #ت# #ه# #ا# #م و# #م# #ل# #ا# #ح# #ا# #ة ، </s>\\n<s> و# #ه# #م# #ا ي# #س# #ت# #م# #ر# #ا# #ن ن# #ه ذ# #ل# #ك ا# #ل# #ي# #و# #م ا# #ل# #ر# #ا# #ئ# #ق ا# #ل# #ص# #ا# #ف ا# #ب# #ل# #ج# #ي# #ل ، و# #ق# #ا# #ل# #ت </s>\\n<s> م# #ا# #ذ# #ا ت# #م# #ن# #؟ </s>\\n<s> ق# #ا# #ل ه# #ت ى م# #ن ر# #و# #ع# #ك ا# #م# #ا ث# #ن# #ا# #ء ا# #ر# #د# #ت ل# #ا# #م# #ل# #ا# #م# #ة# #، و# #ا# #خ# #ذ </s>\\n<s> ي# #ش# #ر# #ح ل# #ه# #ا م# #ا ي# #ع# #ن# #ه ك# #ا# #ن# #ه ح# #د# #ث# #ه# #ا ع# #ن ا# #م# #ر# #ا# #ة غ# #ا# #ئ# #ي# #ة ا# #و ع# #ن ش# #خ# #ص م# #ن </s>\\n<s> ش# #خ# #و ص ا# #ل# #ر# #و# #ا# #ن# #ا# #ت ، و# #ه ت# #ص# #غ# #ى ا# #ل# #ي# #ه م# #س# #ب# #و# #ت# #ة ، م م# #س# #ب# #ر ب# #ح# #ة ، م# #م# #ب# #ت# #س# #م# #ه </s>\\n<s> م ط# #ر# #و# #ب# #ا م# #ت# #ه# #ا# #ل# #ة ، و# #ه# #و ي# #ر# #ى ف# #ي# #ا ي# #ر# #ي م# #ص# #د# #ا# #ق م# #ا ي# #ل# #ا# #ح# #ظ# #ه ع# #ل# #ي# #ا </s>\\n<s> و# #ت# #ح# #د# #ث# #ه# #ا ع# #ن# #ه ، ح# #ت# #ى ك# #ا# #ر خ# #ت# #ا# #م ا# #ل# #ح# #د# #ي# #ت ا# #ق# #ت# #ر# #ا# #ب ا# #ل# #ش# #ف# #ا# #ه د# #ا# #ه# #ة </s>\\n<s> و# #ط# #و# #ا# #ع# #ي# #ة م# #ن# #ك# #ت# #ة م# #ن ن# #ـ# #ك# #ا# #ت# #ه# #ا ا# #ل# #ت# #ى ل# #ا ت# #خ# #ذ# #ل# #ه# #ا ف# #ي ا# #م# #ث# #ا# #ل ه# #ذ# #ه ا# #ل# #م# #و# #ا# #ق# #ي </s>\\n<s> ا# #ل# #ق# #ت# #ه# #ا ا# #ل# #ي# #ه و# #ه ت# #ن# #ن# #ا# #ء# #ى ع# #ن# #ه م# #ر# #ح# #ة ض# #ا# #ح# #ي </s>\\n<s> ا# #م# #د ر# #ب# #ك ع# #ن# #د# #ك م# #ن س# #ا# #ر# #ة ا# #ل# #م# #ظ# #ل# #و# #م# #ة ح# #ر# #ب# #م ك# #ا# #م# #ل ، ف# #ل# #ا ت# #ش# #ك# #ر </s>\\n<s> ت# #ف# #س# #ك ك# #ث# #ي# #ر# #ا ع# #ل ا# #ل# #و# #ف# #ا# #ء </s>\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_file = open(\"ocr_space_output_encoded_\" + \".txt\",\"w\")\n",
    "encoded_file.write(encoded_text)\n",
    "original_file.close()\n",
    "encoded_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try except predicted encoded to predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/anasjawed/Documents/arafix_ocr'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['columbia_aco000270',\n",
       " 'cornell_aco000143',\n",
       " 'aub_aco003198',\n",
       " 'aub_aco002793',\n",
       " 'columbia_aco000484',\n",
       " 'aub_aco003204',\n",
       " 'auc_aco000838',\n",
       " 'cornell_aco000177',\n",
       " 'princeton_aco001005_hi',\n",
       " 'nyu_aco000553',\n",
       " 'columbia_aco000325',\n",
       " 'aub_aco001255']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books = [f for f in os.listdir(\"data/\") if \"sample\" not in f and \"DS_Store\" not in f]\n",
    "books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_suffix = \"_post_edited_encoded\"\n",
    "decoded_suffix = \"_post_edited\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-50-4938ec6328d3>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-50-4938ec6328d3>\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    else:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for b in books:\n",
    "    try:\n",
    "        book_path = \"data/\" + b\n",
    "        book_encoded_path = book_path + \"/\" + b +  encoded_suffix + \"/\"\n",
    "        book_decoded_path = book_path + \"/\" + b + decoded_suffix + \"/\"\n",
    "\n",
    "        mapping_folders = [f for f in os.listdir(book_encoded_path) if \"DS_Store\" not in f]\n",
    "    #     print(mapping_folders)\n",
    "        for mf in mapping_folders:\n",
    "            e_files = [f for f in os.listdir(book_encoded_path + mf) if \"DS_Store\" not in f]\n",
    "            \n",
    "            # make folder in decoded:\n",
    "            try:\n",
    "                os.mkdir(book_decoded_path + mf + \"/\")\n",
    "                print(book_decoded_path + mf + \"/\", made)\n",
    "                \n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            \n",
    "            for f in e_files:\n",
    "                try:\n",
    "                    content = decode(open(book_encoded_path + mf + \"/\" + f, \"r\", encoding = \"utf8\").read())\n",
    "                    output_name = f.replace(\"predicted_encoded\", \"predicted\")\n",
    "                    output_file = open(book_decoded_path + mf + \"/\" + output_name, \"w\", encoding = \"utf8\" )\n",
    "                    output_file.write(content)\n",
    "                    output_file.close()\n",
    "\n",
    "                except:\n",
    "                    print(b, mf, f)\n",
    "                    \n",
    "    except:\n",
    "        pass\n",
    "#         break\n",
    "#     break\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"data/co\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unk Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic alignment - Ossama's code\n",
    "def alignFilesBasic(OneEncodePrefix, OneEncodeFolder, TwoEncodePrefix, TwoEncodeFolder, saveAlignmentAs, alignerLocation, results_prefix):\n",
    "\n",
    "    OneName = OneEncodePrefix + \".txt\"\n",
    "    TwoName = TwoEncodePrefix + \".txt\"\n",
    "\n",
    "    #\"python align_text.py -r ocr_tokenized.txt -c rafed_tokenized.txt -m basic -o sample/sample.ar\"\n",
    "    command = \"python3 \" + alignerLocation + \" -s \" + OneEncodeFolder + OneName + \" -t \" + TwoEncodeFolder + TwoName \n",
    "    command +=  \" -m basic -o \" + saveAlignmentAs + results_prefix\n",
    "\n",
    "    print(command)\n",
    "    p = subprocess.getstatusoutput(command)\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/anasjawed/Documents/aocr/arafix_ocr'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_name = \"columbia_aco000270\"\n",
    "alignerLocation = \"code/ced_word_alignment/align_text.py\"\n",
    "\n",
    "OneEncode = \"ocr_space_output_encoded_\"\n",
    "OneEncodeFolder = \"data/columbia_aco000270/columbia_aco000270_raw_ocr_encoded/\"\n",
    "\n",
    "TwoEncode = \"predicted_encoded_\"\n",
    "TwoEncodeFolder = \"data/columbia_aco000270/columbia_aco000270_post_edited_encoded/columbia_aco000270_model_msa_70m_map_pure_emp2_pg25_top30/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveAlignmentAs = \"data/\" + book_name + \"/\" + book_name + \"_unk/\"\n",
    "results = \"unk_file_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 code/ced_word_alignment/align_text.py -s data/columbia_aco000270/columbia_aco000270_raw_ocr_encoded/ocr_space_output_encoded_9.txt -t data/columbia_aco000270/columbia_aco000270_post_edited_encoded/columbia_aco000270_model_msa_70m_map_pure_emp2_pg25_top30/predicted_encoded_9.txt -m basic -o data/columbia_aco000270/columbia_aco000270_unk/unk_file_9\n",
      "(0, 'Basic alignments are saved to: data/columbia_aco000270/columbia_aco000270_unk/unk_file_9.basic')\n",
      "python3 code/ced_word_alignment/align_text.py -s data/columbia_aco000270/columbia_aco000270_raw_ocr_encoded/ocr_space_output_encoded_10.txt -t data/columbia_aco000270/columbia_aco000270_post_edited_encoded/columbia_aco000270_model_msa_70m_map_pure_emp2_pg25_top30/predicted_encoded_10.txt -m basic -o data/columbia_aco000270/columbia_aco000270_unk/unk_file_10\n",
      "(0, 'Basic alignments are saved to: data/columbia_aco000270/columbia_aco000270_unk/unk_file_10.basic')\n",
      "python3 code/ced_word_alignment/align_text.py -s data/columbia_aco000270/columbia_aco000270_raw_ocr_encoded/ocr_space_output_encoded_11.txt -t data/columbia_aco000270/columbia_aco000270_post_edited_encoded/columbia_aco000270_model_msa_70m_map_pure_emp2_pg25_top30/predicted_encoded_11.txt -m basic -o data/columbia_aco000270/columbia_aco000270_unk/unk_file_11\n",
      "(0, 'Basic alignments are saved to: data/columbia_aco000270/columbia_aco000270_unk/unk_file_11.basic')\n",
      "python3 code/ced_word_alignment/align_text.py -s data/columbia_aco000270/columbia_aco000270_raw_ocr_encoded/ocr_space_output_encoded_12.txt -t data/columbia_aco000270/columbia_aco000270_post_edited_encoded/columbia_aco000270_model_msa_70m_map_pure_emp2_pg25_top30/predicted_encoded_12.txt -m basic -o data/columbia_aco000270/columbia_aco000270_unk/unk_file_12\n",
      "(0, 'Basic alignments are saved to: data/columbia_aco000270/columbia_aco000270_unk/unk_file_12.basic')\n",
      "python3 code/ced_word_alignment/align_text.py -s data/columbia_aco000270/columbia_aco000270_raw_ocr_encoded/ocr_space_output_encoded_13.txt -t data/columbia_aco000270/columbia_aco000270_post_edited_encoded/columbia_aco000270_model_msa_70m_map_pure_emp2_pg25_top30/predicted_encoded_13.txt -m basic -o data/columbia_aco000270/columbia_aco000270_unk/unk_file_13\n",
      "(0, 'Basic alignments are saved to: data/columbia_aco000270/columbia_aco000270_unk/unk_file_13.basic')\n",
      "python3 code/ced_word_alignment/align_text.py -s data/columbia_aco000270/columbia_aco000270_raw_ocr_encoded/ocr_space_output_encoded_14.txt -t data/columbia_aco000270/columbia_aco000270_post_edited_encoded/columbia_aco000270_model_msa_70m_map_pure_emp2_pg25_top30/predicted_encoded_14.txt -m basic -o data/columbia_aco000270/columbia_aco000270_unk/unk_file_14\n",
      "(0, 'Basic alignments are saved to: data/columbia_aco000270/columbia_aco000270_unk/unk_file_14.basic')\n",
      "python3 code/ced_word_alignment/align_text.py -s data/columbia_aco000270/columbia_aco000270_raw_ocr_encoded/ocr_space_output_encoded_15.txt -t data/columbia_aco000270/columbia_aco000270_post_edited_encoded/columbia_aco000270_model_msa_70m_map_pure_emp2_pg25_top30/predicted_encoded_15.txt -m basic -o data/columbia_aco000270/columbia_aco000270_unk/unk_file_15\n",
      "(0, 'Basic alignments are saved to: data/columbia_aco000270/columbia_aco000270_unk/unk_file_15.basic')\n",
      "python3 code/ced_word_alignment/align_text.py -s data/columbia_aco000270/columbia_aco000270_raw_ocr_encoded/ocr_space_output_encoded_16.txt -t data/columbia_aco000270/columbia_aco000270_post_edited_encoded/columbia_aco000270_model_msa_70m_map_pure_emp2_pg25_top30/predicted_encoded_16.txt -m basic -o data/columbia_aco000270/columbia_aco000270_unk/unk_file_16\n",
      "(0, 'Basic alignments are saved to: data/columbia_aco000270/columbia_aco000270_unk/unk_file_16.basic')\n",
      "python3 code/ced_word_alignment/align_text.py -s data/columbia_aco000270/columbia_aco000270_raw_ocr_encoded/ocr_space_output_encoded_17.txt -t data/columbia_aco000270/columbia_aco000270_post_edited_encoded/columbia_aco000270_model_msa_70m_map_pure_emp2_pg25_top30/predicted_encoded_17.txt -m basic -o data/columbia_aco000270/columbia_aco000270_unk/unk_file_17\n",
      "(0, 'Basic alignments are saved to: data/columbia_aco000270/columbia_aco000270_unk/unk_file_17.basic')\n",
      "python3 code/ced_word_alignment/align_text.py -s data/columbia_aco000270/columbia_aco000270_raw_ocr_encoded/ocr_space_output_encoded_18.txt -t data/columbia_aco000270/columbia_aco000270_post_edited_encoded/columbia_aco000270_model_msa_70m_map_pure_emp2_pg25_top30/predicted_encoded_18.txt -m basic -o data/columbia_aco000270/columbia_aco000270_unk/unk_file_18\n",
      "(0, 'Basic alignments are saved to: data/columbia_aco000270/columbia_aco000270_unk/unk_file_18.basic')\n",
      "python3 code/ced_word_alignment/align_text.py -s data/columbia_aco000270/columbia_aco000270_raw_ocr_encoded/ocr_space_output_encoded_19.txt -t data/columbia_aco000270/columbia_aco000270_post_edited_encoded/columbia_aco000270_model_msa_70m_map_pure_emp2_pg25_top30/predicted_encoded_19.txt -m basic -o data/columbia_aco000270/columbia_aco000270_unk/unk_file_19\n",
      "(0, 'Basic alignments are saved to: data/columbia_aco000270/columbia_aco000270_unk/unk_file_19.basic')\n"
     ]
    }
   ],
   "source": [
    "start = 9\n",
    "end = 19 # INCLUSIVE\n",
    "\n",
    "for i in range(start, end + 1):   \n",
    "    OneEncodePrefix = OneEncode + str(i)\n",
    "    TwoEncodePrefix = TwoEncode + str(i)\n",
    "    results_prefix = results + str(i)\n",
    "    alignFilesBasic(OneEncodePrefix, OneEncodeFolder, TwoEncodePrefix, TwoEncodeFolder, saveAlignmentAs, alignerLocation, results_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"data/columbia_aco000270/columbia_aco000270_unk/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix UNK Business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to decode text\n",
    "def decode(l):\n",
    "\t#     l = l.replace(\"+\", \"#\")\n",
    "    # there is an unexpected case in disambig results - #A #B#. \n",
    "    # we are unsure of whether to split or merge this case, and currently we are spliting\n",
    "    l = l.replace(\"# #\", \"\").replace(\"+ \", \"\").replace(\"</s>\", \"\").replace(\"<s>\", \"\")\n",
    "    l = l.replace(\"# #\", \"\").replace(\"+ \", \"\").replace(\"</s>\", \"\").replace(\"<s>\", \"\")\n",
    "    l = l.replace(\"# \", \" \").replace(\" #\", \" \")\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_folder = \"data/columbia_aco000270/columbia_aco000270_post_edited_encoded/columbia_aco000270_model_openiti_70m_map_segmenter_no_unk/\"\n",
    "encoded_prefix = \"predicted_encoded_\"\n",
    "raw_folder = \"data/columbia_aco000270/columbia_aco000270_raw_ocr_encoded/\"\n",
    "raw_prefix = \"ocr_space_output_encoded_\"\n",
    "\n",
    "encoded_output_folder = encoded_folder[:-1] + \"_fixed/\"\n",
    "encoded_output_prefix = \"predicted_encoded_\"\n",
    "decoded_output_folder = \"data/columbia_aco000270/columbia_aco000270_post_edited/\" + encoded_folder.split(\"/\")[-2] + \"_fixed/\"\n",
    "decoded_output_prefix = \"predicted_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/columbia_aco000270/columbia_aco000270_post_edited_encoded/columbia_aco000270_model_openiti_70m_map_segmenter_no_unk_fixed/ made\n",
      "data/columbia_aco000270/columbia_aco000270_post_edited/columbia_aco000270_model_openiti_70m_map_segmenter_no_unk_fixed/ made\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(encoded_output_folder)\n",
    "    print(encoded_output_folder, \"made\")\n",
    "    \n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.mkdir(decoded_output_folder)\n",
    "    print(decoded_output_folder, \"made\")\n",
    "\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_page = 9\n",
    "end_page = 29 # INCLUSIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(start_page, end_page + 1):\n",
    "    unk_lines = open(encoded_folder + encoded_prefix + str(i) + \".txt\", \"r\", encoding = \"utf8\").readlines()\n",
    "    raw_lines = open(raw_folder + raw_prefix + str(i) + \".txt\", \"r\", encoding = \"utf8\").readlines()\n",
    "    \n",
    "    for j in range(len(unk_lines)):\n",
    "        unk_line = unk_lines[j].split(\" \")\n",
    "        raw_line = raw_lines[j].split(\" \")\n",
    "        \n",
    "        if len(unk_line) != len(raw_line):\n",
    "            print(\"page\", i, \"line\", j, \"does not align\")\n",
    "            \n",
    "        else:\n",
    "            for k in range(len(unk_line)):\n",
    "                if unk_line[k].strip() == \"<unk>\":\n",
    "#                     print(\"replacing\")\n",
    "                    unk_line[k] = raw_line[k]\n",
    "                    \n",
    "            unk_lines[j] = \" \".join(unk_line)\n",
    "#             print(unk_lines[j])\n",
    "\n",
    "    encoded_output = open(encoded_output_folder + encoded_output_prefix + str(i) + \".txt\", \"w\", encoding = \"utf8\")\n",
    "    encoded_output.write(\"\".join(unk_lines))\n",
    "    encoded_output.close()\n",
    "    \n",
    "    \n",
    "    decoded_output = open(decoded_output_folder + decode_output_prefix + str(i) + \".txt\", \"w\", encoding = \"utf8\")\n",
    "    decoded_output.write(decode(\"\".join(unk_lines)))\n",
    "    decoded_output.close()\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s> ٢# #٩ </s>\\n',\n",
       " '<s> ا# #ل# #ا# #ت ، و ه# #و ي# #ج# #ن# - ف# #ا# #ل ت# #و# #د أ س# #ي# #د# #ة </s>\\n',\n",
       " '<s> ح# #ض# #ر# #ت# #ف# #ق غ# #ي# #ب# #ت# #ه و# #ل# #ا ت# #ز# #ا# #ل ف# #ي ا# #ن# #ت# #ظ# #ا# #ر# #ه ، و# #ي# #غ# #ا# #و ه# #ه# #ذ ا# #ا# #ل# #و# #ه# #ك </s>\\n',\n",
       " '<s> ي# #ع# #ج# #ل ب# #ا# #ل# #ا# #ل# #ت# #ف# #ا# #ت إ# #ل# #ى ه# #م# -# ا# #ل# #ا# #س# #ت# #ق# #ب# #ا# #ل ل# #ي# #ل ق# #ا# #ل س# #ي# #د# #ة ا# #ل# #ى ت# #ن# #ت# #ظ# #ر# #ه ف# #ي# #ه# #ا </s>\\n',\n",
       " '<s> و# #ل# #م ب# #م# #ض ف# #ذ# #ل# #ك إ# #ل ا# #ل# #ي# #ح# #ة خ# #ا# #ط# #ف# #ة و# #ا خ# #ا# #د# #م ش# #ا# #خ# #ص# #ر ل# #ا ي# #ن# #ب# #س ب# #ح# #ر# #د# #ة </s>\\n',\n",
       " '<s> ل# #ا# #، ع# #ل# #ه أ# #ل# #ا ب# #ص# #ل# #ش# #و# #ا ا# #ل# #أ# #خ# #ب# #ا# #ر ي# #س# #ت# #ح# #ق أ# #ن ي# #ق# #ا# #ل </s>\\n',\n",
       " '<s> و أ </s>\\n',\n",
       " '<s> و# #ي# #س# #ا# #و# #ى ت# #ل# #ل# #ك ا# #ل# #ل# #ه# #ف# #ة ا# #ل# #ى ت# #ع# #ت# #ل# #ج ف# #ي ص# #د# #ر ص# #ا# #ح# #ب# #ن# #ا </s>\\n',\n",
       " '<s> أ ا# #ب# #ا# #ل# #ا# #: </s>\\n',\n",
       " '<s> - أ# #ل# #م ت# #ح# #ض# #ر إ# #ل# #ى ه# #ن# #ا ا# #ل# #س# #ي# #د# #ة ؟ أ# #ل# #م ت# #ق# #ل ش# #ي# #ئ# #ا ؟ </s>\\n',\n",
       " '<s> ف# #ق# #ا# #ل ا# #ل# #خ# #ا# #د# #م ف# #ق# #ف ت# #و# #ر# #ع# #ر# #ي ب# : </s>\\n',\n",
       " '<s> ف# #ا# #\"# #. ا# #ب# #د# #ا# #ي ن# #ا غ# #ا# #ض# #ر# #ا# : ك# #ف ل# #ا ت# #ع# #ل# #؟ أ# #ل# #م ت# #ك# #ن ه# #ن# #ا ؟ ه# #ل ف# #ى </s>\\n',\n",
       " '<s> أ# #و# #ص# #ت# #ك ب# #أ# #ن ت# #ق# #و# #ل ذ# #ل# #ك ؟ </s>\\n',\n",
       " '<s> ق# #ا# #ل ا# #ل# #خ# #ا# #د# #م و# #ف و# #ص# #و# #ت ه# #ا# #ت# #ي# #ج# #ا# #ج# #م ن ي# #س# #ت# #غ# #ر# #ب و# #ل# #ا ي# #ف# #ق# #ه م# #ع# #ن# #ى ه# #ذ# #ا </s>\\n',\n",
       " '<s> ا# #ل# #ا# #ت# #ه# #ا# #م : ي# #ا س# #ي# #د# #ى ق# #ل# #ت ل# #ا ك# #ل# #ا أ# #ع# #ل# #، ل# #أ# #ن# #ك ن# #ز# #ل# #ت م# #ن ه# #ن# #ا و# #أ# #ن ا# #ن# #ز# #ل# #ت </s>\\n',\n",
       " '<s> و# #ر# #ا# #ء# #ك# #ح ا# #ل# #م# #ع# #ت# #ا# #د ف# #ي س# #ا# #ر ا# #ل# #أ# #ر# #ا# #م </s>\\n',\n",
       " '<s> و# #ا# #ث# #ت# #ح ل# #ص# #ا# #ح م# #ن# #ا غ# #ي# #ظ# #ا ، و# #م# #ا# #ر ي# #ن# #ه# #ض ع# #ل# #ه ل# #و# #ل# #ا ا# #ن# #ه ر# #ب </s>\\n',\n",
       " '<s> ا# #ل# #ج# #ل م# #ن أ# #م# #ا# #م# #ه ف# #ت# #ع# #ه إ# #ل# «# ا# #ب ا# #ل# #خ# #د# #م ، و# #ه# #و ي# #ع# #ل# #ن ه# #ب ا# #ل# #ط# #ر# #د و# #أ# #ل# #ا </s>\\n',\n",
       " '<s> ي# #ع# #و# #د ل# #ي ر# #ه و# #ج# #و# #ه م# #ر# #ة ا# #خ# #ر# #ى . و# #ل د# #ي# #ص ع# #ن# #ه إ# #ل# #ا ل# #ع# #د# #ث ا# #ل# #ا# #ن# #ة </s>\\n',\n",
       " '<s> أ# #ب# #ا م# #، و# #ل م# #د أ# #ن# #ش# #ه ل# #ه أ# #ن ا# #ل# #ر# #ج# #ل م# #ع# #ذ# #و# #ر ل# #أ# #ن# #ه ل# #م ي# #أ# #م# #ر# #ه ا# #ل# #ب# #ق# #ا# #ء ف# </s>\\n',\n",
       " '<s> ا# #ل# #م# #ز# #ل ، و# #ق# #د أ# #ن# #س# #ا# #ه أ# #ن ي# #أ# #س# #ه ب# #ا ل# #م ق# #ا# #ء ف# #ب# #ه# #م# #ا ك# #ا# #ن م# #ش# #غ# #و# #ل# #ا ب# #ه# #د# #ن ح# #و# #ا# #ر </s>\\n']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unk_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
