{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Notebook attempts to get the ground truth aligned with the OCR Raw Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import csv\n",
    "import camel_tools.utils.charsets\n",
    "import pyarabic.araby as araby\n",
    "import pyarabic.number as number\n",
    "import difflib\n",
    "from PyPDF2 import PdfFileWriter, PdfFileReader\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_punctuation = [c for c in camel_tools.utils.charsets.UNICODE_PUNCT_CHARSET if 1536 <= ord(c) <= 1791]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/anasjawed/Documents/aocr/arafix_ocr'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_name = \"cornell_aco000143\"\n",
    "book_format = \".pdf\"\n",
    "book_path = \"data/\" + book_name\n",
    "ground_truth_work = book_path + \"/\" + book_name + \"_ground_truth_work/\"\n",
    "\n",
    "### OFFSET CHANGES WITH BOOK \n",
    "offset = -6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_path = book_path + \"/\" + book_name + \"_raw_ocr/\"\n",
    "ocr_prefix = \"ocr_space_output_\"\n",
    "ocr_suffix = \".txt\"\n",
    "\n",
    "truth_path = ground_truth_work\n",
    "truth_prefix = book_name + \"_ground_truth_\"\n",
    "\n",
    "realignment_path = book_path + \"/\" + book_name + \"_realignment/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Ground Truth PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(ground_truth_work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputpdf = PdfFileReader(open(book_path + \"/\" + book_name + \"_ground_truth\" + book_format, \"rb\"))\n",
    "\n",
    "for i in range(inputpdf.numPages):\n",
    "    output = PdfFileWriter()\n",
    "    output.addPage(inputpdf.getPage(i))\n",
    "    with open( ground_truth_work + book_name + \"_ground_truth\" + \"_%s.pdf\" % (i+1), \"wb\") as outputStream:\n",
    "        output.write(outputStream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Ground Truth Text Files\n",
    "Use Adobe Acrobat DC to carry out the PDF to txt conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make ground truth text files (deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tika import parser\n",
    "pdf_files = [f for f in os.listdir(ground_truth_path) if \".pdf\" in f]\n",
    "pdf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract all text from ground_truth pdf and put it in a text file\n",
    "for p in pdf_files:\n",
    "#     print(p)\n",
    "    ground_truth = parser.from_file(ground_truth_path + p)\n",
    "    text = \"\"\n",
    "    \n",
    "    try:\n",
    "        text = \" \".join([\" \".join(c.split(\" \")[::-1]) for c in ground_truth[\"content\"].split(\"\\n\") if c.strip() != \"\"])\n",
    "\n",
    "        text = \"\".join([c for c in text if (c not in arabic_punctuation and 1536 <= ord(c) <= 1791) or c == \" \" ])\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "#     text_file_name = p.replace(\".pdf\", \".txt\")\n",
    "#     text_file = open(ground_truth_path + text_file_name, \"w\", encoding = \"utf8\")\n",
    "#     text_file.write(text)\n",
    "#     text_file.close()\n",
    "    \n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseOssamaBasic(file_name):\n",
    "    df = pd.read_csv(file_name, sep = \"\\t\", header = None, engine=\"python\", quoting=csv.QUOTE_NONE)\n",
    "    df.columns = [\"one\", 'op', \"two\", \"extra\"]\n",
    "    df[\"operation\"] = df.apply(operationName, axis = 1)\n",
    "    return df[[\"operation\", \"one\", \"two\"]]\n",
    "\n",
    "def operationName(row):\n",
    "    if row[\"op\"] == \"=\":\n",
    "        return \"OK\"\n",
    "    \n",
    "    elif row[\"op\"] == \"|\":\n",
    "        return \"SUB\"\n",
    "    \n",
    "    elif row[\"op\"] == \"<\":\n",
    "        return \"INS\"\n",
    "    \n",
    "    else:\n",
    "        return \"DEL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic alignment - Ossama's code\n",
    "def alignFilesBasic(OneEncodePrefix, OneEncodeFolder, TwoEncodePrefix, TwoEncodeFolder, saveAlignmentAs, alignerLocation, results_prefix):\n",
    "\n",
    "    OneName = OneEncodePrefix + \".txt\"\n",
    "    TwoName = TwoEncodePrefix + \".txt\"\n",
    "\n",
    "    #\"python align_text.py -r ocr_tokenized.txt -c rafed_tokenized.txt -m basic -o sample/sample.ar\"\n",
    "    command = \"python3 \" + alignerLocation + \" -s \" + OneEncodeFolder + OneName + \" -t \" + TwoEncodeFolder + TwoName \n",
    "    command +=  \" -m basic -o \" + saveAlignmentAs + results_prefix\n",
    "\n",
    "    print(command)\n",
    "    p = subprocess.getstatusoutput(command)\n",
    "    print(p)\n",
    "#         print()\n",
    "#         break\n",
    "#         if i%50 == 0:\n",
    "#             print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling Part\n",
    "Specify page ranges and make single line files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ocr start page</th>\n",
       "      <th>Ocr end page</th>\n",
       "      <th>Truth start page</th>\n",
       "      <th>Truth end page</th>\n",
       "      <th>Num pages</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>72</td>\n",
       "      <td>39</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73</td>\n",
       "      <td>90</td>\n",
       "      <td>55</td>\n",
       "      <td>68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91</td>\n",
       "      <td>113</td>\n",
       "      <td>69</td>\n",
       "      <td>86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>114</td>\n",
       "      <td>133</td>\n",
       "      <td>87</td>\n",
       "      <td>102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>134</td>\n",
       "      <td>156</td>\n",
       "      <td>103</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>157</td>\n",
       "      <td>173</td>\n",
       "      <td>121</td>\n",
       "      <td>132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>174</td>\n",
       "      <td>194</td>\n",
       "      <td>133</td>\n",
       "      <td>147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ocr start page  Ocr end page  Truth start page  Truth end page  Num pages  \\\n",
       "0              13            31                 9              24        NaN   \n",
       "1              32            50                25              38        NaN   \n",
       "2              51            72                39              54        NaN   \n",
       "3              73            90                55              68        NaN   \n",
       "4              91           113                69              86        NaN   \n",
       "5             114           133                87             102        NaN   \n",
       "6             134           156               103             120        NaN   \n",
       "7             157           173               121             132        NaN   \n",
       "8             174           194               133             147        NaN   \n",
       "\n",
       "   Unnamed: 5  Unnamed: 6  \n",
       "0         NaN         NaN  \n",
       "1         NaN         NaN  \n",
       "2         NaN         NaN  \n",
       "3         NaN         NaN  \n",
       "4         NaN         NaN  \n",
       "5         NaN         NaN  \n",
       "6         NaN         NaN  \n",
       "7         NaN         NaN  \n",
       "8         NaN         NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranges = pd.read_csv(book_path + \"/\" + book_name + \"_\" + \"ranges.csv\")\n",
    "ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir(book_path + \"/\" + book_name + \"_realignment/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir(realignment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "segment:  0 ocr_start:  7 ocr_end:  25 truth_start:  9 truth_end:  24\n",
      "cornell_aco000143_s0_raw_ocr_7-25.txt\n",
      "cornell_aco000143_s0_ground_truth_9-24.txt\n",
      "ocr file written:  cornell_aco000143_s0_raw_ocr_7-25.txt\n",
      "truth file written:  cornell_aco000143_s0_ground_truth_9-24.txt\n",
      "alignment started:  cornell_aco000143_s0_ocr_7-25_truth_9-24\n",
      "python3 code/ced_word_alignment/align_text.py -s data/cornell_aco000143/cornell_aco000143_realignment/cornell_aco000143_s0_ground_truth_9-24.txt -t data/cornell_aco000143/cornell_aco000143_realignment/cornell_aco000143_s0_raw_ocr_7-25.txt -m basic -o data/cornell_aco000143/cornell_aco000143_realignment/cornell_aco000143_s0_ocr_7-25_truth_9-24\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ranges)):\n",
    "    row = ranges.iloc[i]\n",
    "    segment = i\n",
    "\n",
    "    ocr_start = int(row[\"Ocr start page\"]) + offset\n",
    "    ocr_end =  int(row[\"Ocr end page\"]) + offset #INCLUSIVE\n",
    "\n",
    "    truth_start = int(row[\"Truth start page\"])\n",
    "    truth_end = int(row[\"Truth end page\"]) #INCLUSIVE\n",
    "\n",
    "\n",
    "    print(\"\\nsegment: \", segment, \"ocr_start: \", ocr_start, \"ocr_end: \", ocr_end, \"truth_start: \", truth_start, \"truth_end: \", truth_end)\n",
    "    \n",
    "    ocr_file_name = book_name + \"_s\" + str(segment) + \"_raw_ocr_\" + str(ocr_start) + \"-\" + str(ocr_end)  + \".txt\"\n",
    "    print(ocr_file_name)\n",
    "\n",
    "    truth_file_name = book_name + \"_s\" + str(segment) + \"_ground_truth_\" + str(truth_start) + \"-\" + str(truth_end) + \".txt\"\n",
    "    print(truth_file_name)\n",
    "    \n",
    "    \n",
    "    # First do ocr\n",
    "    ocr_line = \"\"\n",
    "    for i in range(ocr_start, ocr_end + 1):\n",
    "#         if i < 10:\n",
    "#             file_name = ocr_prefix + \"00\" + str(i) + ocr_suffix\n",
    "\n",
    "#         elif i <100:\n",
    "#             file_name = ocr_prefix + \"0\" + str(i) + ocr_suffix\n",
    "\n",
    "#         elif i < 1000:\n",
    "#             file_name = ocr_prefix + str(i) + ocr_suffix\n",
    "\n",
    "#         else:\n",
    "#             print(\"fix numbering issue\")\n",
    "#             break\n",
    "\n",
    "        file_name = ocr_prefix + str(i) + ocr_suffix\n",
    "\n",
    "        content = \"\"\n",
    "        content = open(ocr_path + file_name, \"r\", encoding = \"utf8\").read()\n",
    "\n",
    "        try:\n",
    "            content = content.replace(\"\\n\", \" \")\n",
    "            content = \"\".join([c for c in content if (c not in arabic_punctuation and 1536 <= ord(c) <= 1791) or c == \" \" ])\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        ocr_line += content + \" <endpage> \"\n",
    "        \n",
    "        \n",
    "    # write ocr line to the realignment folder\n",
    "    ocr_file = open(realignment_path + ocr_file_name, \"w\", encoding = \"utf8\")\n",
    "    ocr_file.write(ocr_line)\n",
    "    ocr_file.close()\n",
    "    print(\"ocr file written: \", ocr_file_name)\n",
    "    \n",
    "    # Now do ground truth\n",
    "    truth_line = \"\"\n",
    "    for i in range(truth_start, truth_end + 1):\n",
    "\n",
    "        file_name = truth_prefix + str(i) + \".txt\"\n",
    "\n",
    "        content = \"\"\n",
    "        content = open(truth_path + file_name, \"r\", encoding = \"utf8\").read()\n",
    "\n",
    "        try:\n",
    "            content = content.replace(\"\\n\", \" \")\n",
    "            content = \"\".join([c for c in content if (c not in arabic_punctuation and 1536 <= ord(c) <= 1791) or c == \" \" ])\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        truth_line += content + \" \"\n",
    "        \n",
    "    # Write the truth_line\n",
    "    truth_file = open(realignment_path + truth_file_name, \"w\", encoding = \"utf8\")\n",
    "    truth_file.write(truth_line)\n",
    "    truth_file.close()\n",
    "    print(\"truth file written: \", truth_file_name)\n",
    "\n",
    "    #alignment part\n",
    "    ground_truth_file_prefix = realignment_path + truth_file_name.replace(\".txt\", \"\")\n",
    "    raw_file_prefix = realignment_path + ocr_file_name.replace(\".txt\", \"\")\n",
    "    save_alignment_as = realignment_path\n",
    "    results_prefix = book_name + \"_s\" + str(segment) + \"_ocr_\" + str(ocr_start) + \"-\" + str(ocr_end) + \"_truth_\" + str(truth_start) + \"-\" + str(truth_end)\n",
    "    alignerLocation = \"code/ced_word_alignment/align_text.py\"\n",
    "    print(\"alignment started: \", results_prefix)\n",
    "    alignFilesBasic(ground_truth_file_prefix, \"\", raw_file_prefix, \"\", save_alignment_as, alignerLocation, results_prefix)\n",
    "    print(\"alignment done\")\n",
    "    \n",
    "    #Make pages\n",
    "    df = parseOssamaBasic(save_alignment_as + results_prefix + \".basic\")\n",
    "    page = \"\"\n",
    "\n",
    "    page_num = int(results_prefix.replace(book_name, \"\").split(\"_\")[3].split(\"-\")[0])\n",
    "    segment_num = results_prefix.replace(book_name, \"\").split(\"_\")[1].replace(\"s\", \"\")\n",
    "\n",
    "    print(page_num, segment_num)\n",
    "    \n",
    "    segment_path = book_path + \"/\" + book_name + \"_segment_\" + str(segment_num) + \"/\" \n",
    "    os.mkdir(segment_path)\n",
    "    realigned_prefix = book_name + \"_realigned_truth_\"\n",
    "    realigned_prefix = \"ground_truth_\"\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        row = df.iloc[i]\n",
    "        one = row[\"one\"]\n",
    "        two = row[\"two\"]\n",
    "\n",
    "        if two == \"<endpage>\":\n",
    "            to_write = open(segment_path + realigned_prefix + str(page_num) + \".txt\", \"w\", encoding = \"utf8\")\n",
    "            page_num += 1\n",
    "            to_write.write(page)\n",
    "            to_write.close()\n",
    "            page = \"\"\n",
    "\n",
    "        elif str(one) != \"nan\":\n",
    "            page += str(one) + \" \"\n",
    "            \n",
    "    print(\"pages made\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLD SEGMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aub_aco001048_hi_s7_raw_ocr_85-101.txt\n",
      "aub_aco001048_hi_s7_ground_truth_142-165.txt\n"
     ]
    }
   ],
   "source": [
    "ocr_file_name = book_name + \"_s\" + str(segment) + \"_raw_ocr_\" + str(ocr_start) + \"-\" + str(ocr_end)  + \".txt\"\n",
    "print(ocr_file_name)\n",
    "\n",
    "truth_file_name = book_name + \"_s\" + str(segment) + \"_ground_truth_\" + str(truth_start) + \"-\" + str(truth_end) + \".txt\"\n",
    "print(truth_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First do ocr\n",
    "ocr_line = \"\"\n",
    "for i in range(ocr_start, ocr_end + 1):\n",
    "    if i < 10:\n",
    "        file_name = ocr_prefix + \"00\" + str(i) + ocr_suffix\n",
    "        \n",
    "    elif i <100:\n",
    "        file_name = ocr_prefix + \"0\" + str(i) + ocr_suffix\n",
    "        \n",
    "    elif i < 1000:\n",
    "        file_name = ocr_prefix + str(i) + ocr_suffix\n",
    "        \n",
    "    else:\n",
    "        print(\"fix numbering issue\")\n",
    "        break\n",
    "        \n",
    "    content = \"\"\n",
    "    content = open(ocr_path + file_name, \"r\", encoding = \"utf8\").read()\n",
    "    \n",
    "    try:\n",
    "        content = content.replace(\"\\n\", \" \")\n",
    "        content = \"\".join([c for c in content if (c not in arabic_punctuation and 1536 <= ord(c) <= 1791) or c == \" \" ])\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    ocr_line += content + \" <endpage> \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write ocr line to the realignment folder\n",
    "ocr_file = open(realignment_path + ocr_file_name, \"w\", encoding = \"utf8\")\n",
    "ocr_file.write(ocr_line)\n",
    "ocr_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now do ground truth\n",
    "truth_line = \"\"\n",
    "for i in range(truth_start, truth_end + 1):\n",
    "    \n",
    "    file_name = truth_prefix + str(i) + \".txt\"\n",
    "    \n",
    "    content = \"\"\n",
    "    content = open(truth_path + file_name, \"r\", encoding = \"utf8\").read()\n",
    "    \n",
    "    try:\n",
    "        content = content.replace(\"\\n\", \" \")\n",
    "        content = \"\".join([c for c in content if (c not in arabic_punctuation and 1536 <= ord(c) <= 1791) or c == \" \" ])\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    truth_line += content + \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the truth_line\n",
    "truth_file = open(realignment_path + truth_file_name, \"w\", encoding = \"utf8\")\n",
    "truth_file.write(truth_line)\n",
    "truth_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Alignment Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_name = \"aub_aco001048_hi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_file_prefix = realignment_path + truth_file_name.replace(\".txt\", \"\")\n",
    "raw_file_prefix = realignment_path + ocr_file_name.replace(\".txt\", \"\")\n",
    "save_alignment_as = realignment_path\n",
    "results_prefix = book_name + \"_s\" + str(segment) + \"_ocr_\" + str(ocr_start) + \"-\" + str(ocr_end) + \"_truth_\" + str(truth_start) + \"-\" + str(truth_end)\n",
    "alignerLocation = \"code/ced_word_alignment/align_text.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aub_aco001048_hi_s7_ocr_85-101_truth_142-165'"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 code/ced_word_alignment/align_text.py -r data/aub_aco001048_hi/aub_aco001048_hi_realignment/aub_aco001048_hi_s7_ground_truth_142-165.txt -c data/aub_aco001048_hi/aub_aco001048_hi_realignment/aub_aco001048_hi_s7_raw_ocr_85-101.txt -m basic -o data/aub_aco001048_hi/aub_aco001048_hi_realignment/aub_aco001048_hi_s7_ocr_85-101_truth_142-165\n",
      "(0, 'Basic alignments are saved to: data/aub_aco001048_hi/aub_aco001048_hi_realignment/aub_aco001048_hi_s7_ocr_85-101_truth_142-165.basic')\n"
     ]
    }
   ],
   "source": [
    "alignFilesBasic(ground_truth_file_prefix, \"\", raw_file_prefix, \"\", save_alignment_as, alignerLocation, results_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make New Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = parseOssamaBasic(save_alignment_as + results_prefix + \".basic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>operation</th>\n",
       "      <th>one</th>\n",
       "      <th>two</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>INS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;endpage&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>INS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;endpage&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>INS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;endpage&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>INS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;endpage&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>INS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;endpage&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     operation  one        two\n",
       "309        INS  NaN  <endpage>\n",
       "770        INS  NaN  <endpage>\n",
       "1076       INS  NaN  <endpage>\n",
       "1462       INS  NaN  <endpage>\n",
       "1814       INS  NaN  <endpage>"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"two\"] == \"<endpage>\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 7\n"
     ]
    }
   ],
   "source": [
    "page = \"\"\n",
    "\n",
    "page_num = int(results_prefix.replace(book_name, \"\").split(\"_\")[3].split(\"-\")[0])\n",
    "segment_num = results_prefix.replace(book_name, \"\").split(\"_\")[1].replace(\"s\", \"\")\n",
    "\n",
    "print(page_num, segment_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_path = book_path + \"/\" + book_name + \"_segment\" + str(segment_num) + \"/\" \n",
    "os.mkdir(segment_path)\n",
    "realigned_prefix = book_name + \"_realigned_truth_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    row = df.iloc[i]\n",
    "    one = row[\"one\"]\n",
    "    two = row[\"two\"]\n",
    "    \n",
    "    if two == \"<endpage>\":\n",
    "        to_write = open(segment_path + realigned_prefix + str(page_num) + \".txt\", \"w\", encoding = \"utf8\")\n",
    "        page_num += 1\n",
    "        to_write.write(page)\n",
    "        to_write.close()\n",
    "        page = \"\"\n",
    "        \n",
    "    elif str(one) != \"nan\":\n",
    "        page += str(one) + \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
